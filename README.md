# Office Category Prediction - æ¨¡å—åŒ–æœºå™¨å­¦ä¹ é¡¹ç›®

ä¸€ä¸ªå®Œæ•´çš„ã€æ¨¡å—åŒ–çš„æœºå™¨å­¦ä¹ è®­ç»ƒæ¡†æ¶ï¼Œç”¨äºåŠå…¬å®¤ç±»åˆ«åˆ†ç±»ä»»åŠ¡ã€‚

---

## ğŸ“¦ å®‰è£…

```bash
# åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆæ¨èæ–°æ‰‹ï¼‰

```bash
# æ­¥éª¤ 1: æ•°æ®æ¢ç´¢ï¼ˆäº†è§£æ•°æ®ï¼‰
python main.py --mode eda

# æ­¥éª¤ 2: è®­ç»ƒæ¨¡å‹
python main.py --mode train

# æ­¥éª¤ 3: ç”Ÿæˆé¢„æµ‹
python main.py --mode predict

# æ­¥éª¤ 4: ç‰¹å¾å®¡è®¡ï¼ˆåˆ†æç‰¹å¾é‡è¦æ€§ï¼‰
python main.py --mode audit
```

**è¾“å‡ºæ–‡ä»¶ï¼š**
- æ¨¡å‹ï¼š`outputs/models/pipeline.joblib`
- é¢„æµ‹ï¼š`outputs/predictions/submission.csv`
- æŒ‡æ ‡ï¼š`outputs/metrics/metrics.json`

### 2. é«˜çº§è®­ç»ƒé€‰é¡¹

```bash
# äº¤å‰éªŒè¯ï¼ˆæ›´å¯é çš„æ€§èƒ½è¯„ä¼°ï¼‰
python main.py --mode cv

# è¶…å‚æ•°è°ƒä¼˜ï¼ˆå¯»æ‰¾æœ€ä½³å‚æ•°ï¼‰
python main.py --mode tune
```

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
AI1010Final/
â”œâ”€â”€ configs/                    # âš™ï¸ é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ config.py              # æ‰€æœ‰å‚æ•°éƒ½åœ¨è¿™é‡Œ
â”‚
â”œâ”€â”€ feature_engineering/       # ğŸ”§ ç‰¹å¾å·¥ç¨‹
â”‚   â”œâ”€â”€ encoders.py           # ç¼–ç å™¨ï¼ˆé¢‘ç‡ã€ç›®æ ‡ç¼–ç ï¼‰
â”‚   â”œâ”€â”€ wide_features.py      # æ´¾ç”Ÿç‰¹å¾ï¼ˆ40+ ä¸ªï¼‰
â”‚   â”œâ”€â”€ transformers.py       # è½¬æ¢å™¨ï¼ˆlogã€ç¼ºå¤±å€¼ï¼‰
â”‚   â””â”€â”€ preprocessor.py       # é¢„å¤„ç†ç®¡é“ç»„è£…
â”‚
â”œâ”€â”€ modeling/                  # ğŸ¤– æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ xgboost_model.py      # XGBoost æ¨¡å‹
â”‚   â””â”€â”€ ensemble.py           # é›†æˆæ¨¡å‹
â”‚
â”œâ”€â”€ training/                  # ğŸ“ è®­ç»ƒé€»è¾‘
â”‚   â”œâ”€â”€ trainer.py            # å•æ¬¡è®­ç»ƒ
â”‚   â””â”€â”€ cross_validator.py    # äº¤å‰éªŒè¯
â”‚
â”œâ”€â”€ hyperparameter_tuning/    # ğŸ” è¶…å‚æ•°ä¼˜åŒ–
â”‚   â””â”€â”€ tuner.py              # Optuna è°ƒä¼˜
â”‚
â”œâ”€â”€ data_exploration/         # ğŸ“Š æ•°æ®åˆ†æ
â”‚   â”œâ”€â”€ exploratory_analysis.py  # EDA
â”‚   â””â”€â”€ feature_audit.py         # ç‰¹å¾å®¡è®¡
â”‚
â”œâ”€â”€ data_cleaning/            # ğŸ§¹ æ•°æ®æ¸…æ´—
â”œâ”€â”€ utils/                    # ğŸ› ï¸ å·¥å…·å‡½æ•°
â”œâ”€â”€ main.py                   # ğŸšª ä¸»å…¥å£
â””â”€â”€ datasets/                 # ğŸ“ æ•°æ®ç›®å½•
```

---

## ğŸ¯ è®­ç»ƒå·¥ä½œæµç¨‹

### æ–¹æ¡ˆ A: å¿«é€Ÿå®éªŒï¼ˆå•æ¬¡è®­ç»ƒï¼‰

```
æ•°æ®åŠ è½½ â†’ ç‰¹å¾å·¥ç¨‹ â†’ è®­ç»ƒæ¨¡å‹ â†’ è¯„ä¼° â†’ é¢„æµ‹
   â†“           â†“          â†“        â†“      â†“
office_   preprocessor  XGBoost  metrics  submission.csv
train.csv  pipeline               .json
```

**å‘½ä»¤ï¼š**
```bash
python main.py --mode train   # è®­ç»ƒ
python main.py --mode predict # é¢„æµ‹
```

**é€‚ç”¨åœºæ™¯ï¼š** å¿«é€Ÿè¿­ä»£ã€æµ‹è¯•æ–°ç‰¹å¾

---

### æ–¹æ¡ˆ B: å¯é è¯„ä¼°ï¼ˆäº¤å‰éªŒè¯ï¼‰

```
æ•°æ®åŠ è½½ â†’ 5æŠ˜äº¤å‰éªŒè¯ â†’ èšåˆç»“æœ
   â†“           â†“            â†“
office_    æ¯æŠ˜è®­ç»ƒ+è¯„ä¼°   mean Â± std
train.csv                  metrics
```

**å‘½ä»¤ï¼š**
```bash
python main.py --mode cv
```

**é€‚ç”¨åœºæ™¯ï¼š** æœ€ç»ˆæ¨¡å‹é€‰æ‹©ã€æ€§èƒ½æŠ¥å‘Š

---

### æ–¹æ¡ˆ C: å‚æ•°ä¼˜åŒ–ï¼ˆè¶…å‚æ•°è°ƒä¼˜ï¼‰

```
å®šä¹‰æœç´¢ç©ºé—´ â†’ Optuna ä¼˜åŒ– â†’ æ‰¾åˆ°æœ€ä½³å‚æ•° â†’ é‡æ–°è®­ç»ƒ
      â†“              â†“              â†“            â†“
  config.py     100 trials    best_params   final model
```

**å‘½ä»¤ï¼š**
```bash
python main.py --mode tune  # è°ƒä¼˜
# ç„¶åå°†æœ€ä½³å‚æ•°å¤åˆ¶åˆ° configs/config.py
python main.py --mode train # ç”¨æœ€ä½³å‚æ•°è®­ç»ƒ
```

**é€‚ç”¨åœºæ™¯ï¼š** æ€§èƒ½è°ƒä¼˜ã€ç«èµ›æåˆ†

---

## âš™ï¸ é…ç½®ç®¡ç†

**æ‰€æœ‰å‚æ•°éƒ½åœ¨ `configs/config.py` ä¸­é›†ä¸­ç®¡ç†ï¼**

### å¸¸ç”¨é…ç½®ç¤ºä¾‹

```python
# configs/config.py

# 1. ä¿®æ”¹è®­ç»ƒå‚æ•°
class TrainConfig:
    test_size = 0.2        # éªŒè¯é›†æ¯”ä¾‹
    n_splits = 5           # äº¤å‰éªŒè¯æŠ˜æ•°
    use_early_stopping = True  # æ—©åœ

# 2. ä¿®æ”¹æ¨¡å‹å‚æ•°
class XGBParams:
    n_estimators = 1500    # æ ‘çš„æ•°é‡
    learning_rate = 0.06   # å­¦ä¹ ç‡
    max_depth = 4          # æ ‘æ·±åº¦
    subsample = 0.75       # æ ·æœ¬é‡‡æ ·
    
# 3. ä¿®æ”¹ç‰¹å¾å·¥ç¨‹
class Columns:
    # ä½¿ç”¨é¢‘ç‡ç¼–ç çš„åˆ—
    freq_encoding_cols = ['RoofType', 'ExteriorCovering1']
    
    # ä½¿ç”¨ç›®æ ‡ç¼–ç çš„åˆ—
    target_encoding_cols = ['ZoningClassification', 'BuildingType']
```

**ä¿®æ”¹é…ç½®åæ— éœ€æ”¹ä»£ç ï¼Œç›´æ¥è¿è¡Œå³å¯ï¼**

---

## ğŸ”§ å¦‚ä½•æ·»åŠ æ–°åŠŸèƒ½

### 1ï¸âƒ£ æ·»åŠ æ–°ç‰¹å¾

**ä½ç½®ï¼š** `feature_engineering/wide_features.py`

```python
class WideFeatureBuilder(BaseEstimator, TransformerMixin):
    def _add_custom_features(self, df: pd.DataFrame, out: Dict[str, Any]):
        """åœ¨è¿™é‡Œæ·»åŠ ä½ çš„è‡ªå®šä¹‰ç‰¹å¾"""
        
        # ç¤ºä¾‹ 1: ç®€å•äº¤äº’ç‰¹å¾
        out["QualityTimesArea"] = df["OverallQual"] * df["GrLivArea"]
        
        # ç¤ºä¾‹ 2: æ¡ä»¶ç‰¹å¾
        out["HasPool"] = (df["PoolArea"] > 0).astype(int)
        
        # ç¤ºä¾‹ 3: æ¯”ç‡ç‰¹å¾
        total_area = df["TotalBsmtSF"] + df["GrLivArea"]
        out["BasementRatio"] = df["TotalBsmtSF"] / (total_area + 1e-6)
        
        # ç¤ºä¾‹ 4: é¢†åŸŸçŸ¥è¯†ç‰¹å¾
        out["PricePerSqft"] = df["SalePrice"] / (df["GrLivArea"] + 1)
```

**ç„¶åè¿è¡Œï¼š**
```bash
python main.py --mode train  # æ–°ç‰¹å¾ä¼šè‡ªåŠ¨ä½¿ç”¨
```

---

### 2ï¸âƒ£ æ·»åŠ æ–°æ¨¡å‹

**æ­¥éª¤ 1:** åœ¨ `modeling/` åˆ›å»ºæ–°æ–‡ä»¶ï¼Œå¦‚ `lightgbm_model.py`

```python
from modeling import BaseModel
import lightgbm as lgb

class LightGBMModel(BaseModel):
    def build_model(self, **params):
        """åˆå§‹åŒ–æ¨¡å‹"""
        self.model_ = lgb.LGBMClassifier(**params)
        return self.model_
    
    def fit(self, X, y, **kwargs):
        """è®­ç»ƒ"""
        eval_set = kwargs.get('eval_set', None)
        self.model_.fit(
            X, y,
            eval_set=eval_set,
            callbacks=[lgb.early_stopping(50)]
        )
        return self
    
    def predict(self, X):
        """é¢„æµ‹"""
        return self.model_.predict(X)
```

**æ­¥éª¤ 2:** åœ¨ `main.py` ä¸­æ·»åŠ å¯¹æ–°æ¨¡å‹çš„æ”¯æŒ

```python
# main.py ä¸­æ‰¾åˆ°æ¨¡å‹åˆ›å»ºéƒ¨åˆ†
if config.models.model_type == "xgboost":
    model = XGBoostModel(config=config.models.xgb_params)
elif config.models.model_type == "lightgbm":  # æ–°å¢
    from modeling.lightgbm_model import LightGBMModel
    model = LightGBMModel(config=config.models.lgb_params)
```

**æ­¥éª¤ 3:** åœ¨ `configs/config.py` æ·»åŠ é…ç½®

```python
@dataclass
class ModelsConfig:
    model_type: str = "lightgbm"  # ä¿®æ”¹è¿™é‡Œ
    lgb_params: dict = field(default_factory=lambda: {
        'n_estimators': 1000,
        'learning_rate': 0.05,
        ...
    })
```

---

### 3ï¸âƒ£ æ·»åŠ æ–°ç¼–ç å™¨

**ä½ç½®ï¼š** `feature_engineering/encoders.py`

```python
from sklearn.base import BaseEstimator, TransformerMixin

class MyCustomEncoder(BaseEstimator, TransformerMixin):
    """è‡ªå®šä¹‰ç¼–ç å™¨"""
    
    def __init__(self, columns=None):
        self.columns = columns
        self.mapping_ = {}
    
    def fit(self, X, y=None):
        """å­¦ä¹ ç¼–ç æ˜ å°„"""
        for col in self.columns:
            # ä½ çš„ç¼–ç é€»è¾‘
            self.mapping_[col] = X[col].value_counts().to_dict()
        return self
    
    def transform(self, X):
        """åº”ç”¨ç¼–ç """
        X = X.copy()
        for col in self.columns:
            X[col] = X[col].map(self.mapping_[col]).fillna(0)
        return X
```

**ç„¶ååœ¨ `feature_engineering/preprocessor.py` ä¸­ä½¿ç”¨ï¼š**

```python
from .encoders import MyCustomEncoder

# åœ¨ build_preprocessor å‡½æ•°ä¸­æ·»åŠ 
transformers.append((
    "my_encoder",
    MyCustomEncoder(columns=['MyColumn']),
    ['MyColumn']
))
```

---

### 4ï¸âƒ£ ä¿®æ”¹è¶…å‚æ•°æœç´¢ç©ºé—´

**ä½ç½®ï¼š** `hyperparameter_tuning/tuner.py`

```python
def _suggest_xgb_params(self, trial: optuna.Trial) -> dict:
    """å®šä¹‰æœç´¢ç©ºé—´"""
    return {
        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        
        # æ·»åŠ æ–°å‚æ•°
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
        'gamma': trial.suggest_float('gamma', 0, 5),
    }
```

---

## ğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜

```
outputs/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pipeline.joblib           # å®Œæ•´è®­ç»ƒç®¡é“ï¼ˆåŒ…å«é¢„å¤„ç†+æ¨¡å‹ï¼‰
â”‚   â””â”€â”€ cv/
â”‚       â”œâ”€â”€ fold_1.joblib          # å„æŠ˜æ¨¡å‹
â”‚       â””â”€â”€ cv_summary.json        # CV ç»“æœæ±‡æ€»
â”‚
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ metrics.json               # è¯„ä¼°æŒ‡æ ‡ï¼ˆç²¾åº¦ã€å¬å›ã€F1ç­‰ï¼‰
â”‚
â”œâ”€â”€ predictions/
â”‚   â””â”€â”€ submission.csv             # æµ‹è¯•é›†é¢„æµ‹ç»“æœ
â”‚
â”œâ”€â”€ eda_report.json                # æ•°æ®æ¢ç´¢æŠ¥å‘Š
â”œâ”€â”€ feature_audit.json             # ç‰¹å¾é‡è¦æ€§åˆ†æ
â””â”€â”€ tuning_results.json            # è¶…å‚æ•°è°ƒä¼˜ç»“æœ
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### å…¸å‹å·¥ä½œæµç¨‹

```bash
# 1. ç¬¬ä¸€æ¬¡è®­ç»ƒ
python main.py --mode eda      # äº†è§£æ•°æ®
python main.py --mode train    # å¿«é€Ÿè®­ç»ƒ
python main.py --mode audit    # åˆ†æç‰¹å¾

# 2. æ”¹è¿›ç‰¹å¾ï¼ˆä¿®æ”¹ wide_features.pyï¼‰
python main.py --mode train    # æµ‹è¯•æ–°ç‰¹å¾

# 3. å‚æ•°è°ƒä¼˜
python main.py --mode tune     # æ‰¾æœ€ä½³å‚æ•°
# å°†æœ€ä½³å‚æ•°å¤åˆ¶åˆ° configs/config.py

# 4. æœ€ç»ˆè®­ç»ƒ
python main.py --mode cv       # äº¤å‰éªŒè¯è¯„ä¼°
python main.py --mode train    # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
python main.py --mode predict  # ç”Ÿæˆæäº¤æ–‡ä»¶
```

### è°ƒè¯•æŠ€å·§

```bash
# 1. æ£€æŸ¥æ•°æ®
python main.py --mode eda

# 2. æ£€æŸ¥ç‰¹å¾é‡è¦æ€§
python main.py --mode audit

# 3. æµ‹è¯•æ–°ç‰¹å¾ï¼ˆä¿®æ”¹ configs/config.py ä¸­çš„ test_sizeï¼‰
# test_size = 0.5  # åŠ å¿«è®­ç»ƒé€Ÿåº¦
python main.py --mode train
```

---

## ğŸ” å¸¸è§é—®é¢˜

**Q: å¦‚ä½•å¿«é€Ÿæµ‹è¯•æ–°ç‰¹å¾ï¼Ÿ**
```python
# configs/config.py
class TrainConfig:
    test_size = 0.5  # å‡å°‘è®­ç»ƒæ•°æ®ï¼ŒåŠ å¿«é€Ÿåº¦
    
class XGBParams:
    n_estimators = 100  # å‡å°‘æ ‘çš„æ•°é‡
```

**Q: è®­ç»ƒå¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ**
```python
# configs/config.py
class XGBParams:
    n_jobs = -1  # ä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒ
    tree_method = 'hist'  # ä½¿ç”¨æ›´å¿«çš„ç®—æ³•
```

**Q: å¦‚ä½•ä¿å­˜å¤šä¸ªæ¨¡å‹ç‰ˆæœ¬ï¼Ÿ**
```bash
python main.py --mode train
# æ‰‹åŠ¨é‡å‘½åæ¨¡å‹
mv outputs/models/pipeline.joblib outputs/models/pipeline_v1.joblib
```

---

## ğŸ“š æ ¸å¿ƒç‰¹å¾

- âœ… **æ¨¡å—åŒ–è®¾è®¡** - æ¯ä¸ªåŠŸèƒ½ç‹¬ç«‹ï¼Œæ˜“äºä¿®æ”¹
- âœ… **é…ç½®é©±åŠ¨** - ä¿®æ”¹å‚æ•°æ— éœ€æ”¹ä»£ç 
- âœ… **Sklearn å…¼å®¹** - æ‰€æœ‰è½¬æ¢å™¨éµå¾ªæ ‡å‡†æ¥å£
- âœ… **å®Œæ•´ç®¡é“** - é¢„å¤„ç† + æ¨¡å‹ä¸€ä½“åŒ–
- âœ… **40+ ç‰¹å¾** - æ¶µç›–å¹´é¾„ã€é¢ç§¯ã€è´¨é‡ã€äº¤äº’ç­‰
- âœ… **å¤šç§è®­ç»ƒæ¨¡å¼** - å•æ¬¡/äº¤å‰éªŒè¯/è°ƒä¼˜
- âœ… **ç‰¹å¾åˆ†æ** - é‡è¦æ€§/æ¼‚ç§»/ç›¸å…³æ€§

---

**å¼€å§‹è®­ç»ƒå§ï¼** ğŸš€

```bash
python main.py --mode train
```
# Office Category Prediction - ML Pipeline

A modular, production-ready machine learning pipeline for office category classification.

## ğŸ“ Project Structure

```
AI1010Final/
â”œâ”€â”€ configs/                    # Configuration management
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py              # Centralized configuration
â”‚
â”œâ”€â”€ data_cleaning/             # Data cleaning utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ column_types.py        # Column type inference
â”‚   â”œâ”€â”€ missing_handler.py     # Missing value handling
â”‚   â””â”€â”€ outlier_handler.py     # Outlier detection & handling
â”‚
â”œâ”€â”€ data_exploration/          # EDA and feature auditing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ exploratory_analysis.py # Basic EDA
â”‚   â””â”€â”€ feature_audit.py       # Feature importance & drift analysis
â”‚
â”œâ”€â”€ feature_engineering/       # Feature engineering modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ encoders.py           # Frequency & target encoding
â”‚   â”œâ”€â”€ wide_features.py      # Derived feature builder
â”‚   â”œâ”€â”€ statistical_features.py # Statistical aggregations
â”‚   â”œâ”€â”€ transformers.py       # Log transforms, etc.
â”‚   â””â”€â”€ preprocessor.py       # Main preprocessor assembly
â”‚
â”œâ”€â”€ modeling/                  # Model definitions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py         # Abstract base class
â”‚   â”œâ”€â”€ xgboost_model.py      # XGBoost wrapper
â”‚   â””â”€â”€ ensemble.py           # Ensemble methods
â”‚
â”œâ”€â”€ training/                  # Training logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py            # Single split trainer
â”‚   â””â”€â”€ cross_validator.py   # K-fold cross-validation
â”‚
â”œâ”€â”€ hyperparameter_tuning/    # Hyperparameter optimization
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ tuner.py             # Optuna-based tuning
â”‚
â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py            # Logging utilities
â”‚   â””â”€â”€ metrics.py           # Evaluation metrics
â”‚
â”œâ”€â”€ datasets/                 # Data directory
â”‚   â”œâ”€â”€ office_train.csv
â”‚   â””â”€â”€ office_test.csv
â”‚
â”œâ”€â”€ outputs/                  # Output directory (created automatically)
â”‚   â”œâ”€â”€ models/              # Trained models
â”‚   â”œâ”€â”€ metrics/             # Evaluation metrics
â”‚   â”œâ”€â”€ predictions/         # Test predictions
â”‚   â””â”€â”€ logs/               # Log files
â”‚
â”œâ”€â”€ main.py                  # Main entry point
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Exploratory Data Analysis

```bash
python main.py --mode eda
```

This will:
- Analyze missing values
- Show target distribution
- Compute cardinality
- Generate statistics
- Save report to `outputs/eda_report.json`

### 3. Train Model (Single Split)

```bash
python main.py --mode train
```

This will:
- Load and split data (80/20)
- Build preprocessing pipeline
- Train XGBoost model
- Evaluate on validation set
- Save model to `outputs/models/pipeline.joblib`
- Save metrics to `outputs/metrics/metrics.json`

### 4. Cross-Validation Training

```bash
python main.py --mode cv
```

This will:
- Perform 5-fold stratified cross-validation
- Train model on each fold
- Aggregate results with mean Â± std
- Save summary to `outputs/models/cv/cv_summary.json`

### 5. Hyperparameter Tuning

```bash
python main.py --mode tune
```

This will:
- Use Optuna for Bayesian optimization
- Run 100 trials (configurable)
- Save best parameters to `outputs/tuning_results.json`

### 6. Feature Audit

```bash
python main.py --mode audit
```

This will:
- Compute feature importance
- Run permutation importance
- Check for train/val drift (adversarial validation)
- Identify highly correlated features
- Save report to `outputs/feature_audit.json`

### 7. Make Predictions

```bash
python main.py --mode predict --model_path outputs/models/pipeline.joblib
```

This will:
- Load trained model
- Make predictions on test set
- Save to `outputs/predictions/submission.csv`

## ğŸ”§ Configuration

All configuration is centralized in `configs/config.py`. Key sections:

### Paths
```python
train_csv = "datasets/office_train.csv"
test_csv = "datasets/office_test.csv"
output_dir = "outputs"
```

### Model Parameters
```python
xgb_params = {
    'n_estimators': 1500,
    'learning_rate': 0.06,
    'max_depth': 4,
    'subsample': 0.75,
    'colsample_bytree': 0.55,
    'reg_lambda': 10.0,
    'reg_alpha': 3.0,
    ...
}
```

### Feature Engineering
```python
freq_encoding_cols = ['RoofType', 'ExteriorCovering1', 'FoundationType']
target_encoding_cols = ['ZoningClassification', 'BuildingType', ...]
```

### Training
```python
test_size = 0.2
n_splits = 5
use_class_weights = True
use_early_stopping = True
```

## ğŸ§ª Feature Engineering Pipeline

The pipeline includes:

1. **Missing Value Handling**
   - Median imputation for numeric features
   - Constant imputation for categorical features
   - Missing indicators

2. **Encoding**
   - Frequency encoding for high-cardinality features
   - Target encoding with Laplace smoothing
   - One-hot encoding for low-cardinality features

3. **Wide Features** (40+ derived features)
   - Age features: BuildingAge, YearsSinceRenovation
   - Area features: TotalLivingArea, TotalBasementArea
   - Ratio features: PlotCoverage, RoomDensity, etc.
   - Quality combinations: OverallQuality, ExteriorScore
   - Temporal features: SeasonListed, BuildingLifeStage
   - Interaction features: QualityAreaProximity
   - Domain knowledge: RoomSizeAdequacy, ParkingAdequacy

4. **Statistical Aggregations**
   - Group-level z-scores
   - Relative shifts from group mean

5. **Transformations**
   - Log1p for skewed features (PlotSize)

## ğŸ“Š Model Performance

The pipeline is optimized for accuracy with:
- Stratified sampling
- Class weighting for imbalanced data
- Early stopping to prevent overfitting
- Comprehensive regularization (L1/L2)

Expected validation accuracy: **~75-80%** (depending on feature selection and tuning)

## ğŸ”¬ Advanced Usage

### Custom Configuration

Create a custom config and pass it:

```python
from configs import Config

config = Config()
config.models.xgb_params['n_estimators'] = 2000
config.training.n_splits = 10

# Use in your code
from training import Trainer
trainer = Trainer(config)
trainer.run()
```

### Programmatic API

You can also use the modules programmatically:

```python
from configs import Config
from training import Trainer
from modeling import XGBoostModel

# Setup
config = Config()
trainer = Trainer(config)

# Load data
X, y = trainer.load_data()
X_train, X_val, y_train, y_val = trainer.split_data(X, y)

# Build preprocessor
trainer.build_preprocessor(X_train)

# Train
model = XGBoostModel(config=config.models.xgb_params)
results = trainer.train(model, X_train, y_train, X_val, y_val)
```

### Adding New Features

Extend `WideFeatureBuilder` in `feature_engineering/wide_features.py`:

```python
def _add_custom_features(self, df: pd.DataFrame, out: Dict[str, Any]):
    """Add your custom features."""
    # Example: Interaction between two features
    out["CustomFeature"] = df["Feature1"] * df["Feature2"]
```

## ğŸ“ Development Notes

### Design Principles

1. **Modularity**: Each component is self-contained and reusable
2. **Extensibility**: Easy to add new features, models, or strategies
3. **Configurability**: Centralized configuration for easy experimentation
4. **Sklearn Compatibility**: All transformers follow sklearn API
5. **Production Ready**: Proper logging, error handling, serialization

### Testing

```bash
# Run tests (if you add them)
pytest tests/

# Test individual modules
python -c "from configs import Config; print(Config())"
```

### Adding New Models

1. Create model class in `modeling/` inheriting from `BaseModel`
2. Implement `build_model()`, `fit()`, `predict()` methods
3. Update `main.py` to support new model

Example:

```python
from modeling import BaseModel

class MyCustomModel(BaseModel):
    def build_model(self, **kwargs):
        # Your model initialization
        pass
    
    def fit(self, X, y, **kwargs):
        # Training logic
        pass
    
    def predict(self, X):
        # Prediction logic
        pass
```

## ğŸ› Troubleshooting

### Common Issues

1. **Import errors**: Ensure virtual environment is activated
2. **Memory issues**: Reduce `n_estimators` or use sampling
3. **Optuna not found**: Install with `pip install optuna`

### Performance Tips

- Use `n_jobs=-1` for parallel processing
- Enable early stopping to save time
- Start with fewer CV folds (e.g., 3) during development
- Use hyperparameter tuning sparingly (time-consuming)

## ğŸ“š References

- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Scikit-learn](https://scikit-learn.org/)
- [Optuna](https://optuna.org/)

## ğŸ¤ Contributing

Feel free to:
- Add new feature engineering techniques
- Implement additional models
- Improve hyperparameter search spaces
- Add visualization utilities
- Write tests

## ğŸ“„ License

This project is for educational purposes.

---

**Happy Modeling! ğŸ‰**

## âœ¨ é‡æ„å®Œæˆï¼é¡¹ç›®å·²å…¨éƒ¨å®Œæˆ

### ğŸ“Š é¡¹ç›®ç»Ÿè®¡

**æ¨¡å—ç»Ÿè®¡:**
```
âœ… configs/               - é…ç½®ç®¡ç† (2 files)
âœ… data_cleaning/         - æ•°æ®æ¸…æ´— (4 files)
âœ… data_exploration/      - æ•°æ®æ¢ç´¢ (3 files)
âœ… feature_engineering/   - ç‰¹å¾å·¥ç¨‹ (6 files)
âœ… modeling/              - æ¨¡å‹å®šä¹‰ (4 files)
âœ… training/              - è®­ç»ƒé€»è¾‘ (3 files)
âœ… hyperparameter_tuning/ - è¶…å‚è°ƒä¼˜ (2 files)
âœ… utils/                 - å·¥å…·å‡½æ•° (3 files)
âœ… main.py                - ä¸»å…¥å£ (1 file)
```

**æ–‡æ¡£:**
```
âœ… README.md           - å®Œæ•´ç”¨æˆ·æŒ‡å— (500+ è¡Œ)
âœ… ARCHITECTURE.md     - æ¶æ„è®¾è®¡æ–‡æ¡£ (600+ è¡Œ)
```

---

### ğŸ¯ æ ¸å¿ƒç‰¹æ€§

#### 1. **å®Œå…¨æ¨¡å—åŒ–** âœ¨
- æ¯ä¸ªæ¨¡å—èŒè´£å•ä¸€ã€æ¸…æ™°
- æ˜“äºæµ‹è¯•å’Œç»´æŠ¤
- æ”¯æŒç‹¬ç«‹ä½¿ç”¨æˆ–ç»„åˆä½¿ç”¨

#### 2. **é…ç½®é©±åŠ¨** âš™ï¸
- æ‰€æœ‰å‚æ•°é›†ä¸­åœ¨ `configs/config.py`
- æ— éœ€ä¿®æ”¹ä»£ç å³å¯å®éªŒ
- æ˜“äºç‰ˆæœ¬æ§åˆ¶å’Œå¤ç°

#### 3. **CLI æ¥å£** ğŸ–¥ï¸
```bash
python main.py --mode eda      # æ•°æ®æ¢ç´¢
python main.py --mode train    # å•æ¬¡è®­ç»ƒ
python main.py --mode cv       # äº¤å‰éªŒè¯
python main.py --mode tune     # è¶…å‚è°ƒä¼˜
python main.py --mode predict  # é¢„æµ‹
python main.py --mode audit    # ç‰¹å¾å®¡è®¡
```

#### 4. **å®Œæ•´ç‰¹å¾å·¥ç¨‹** ğŸ”§
- âœ… é¢‘ç‡ç¼–ç 
- âœ… ç›®æ ‡ç¼–ç ï¼ˆå¸¦å¹³æ»‘ï¼‰
- âœ… 40+ æ´¾ç”Ÿç‰¹å¾
  - å¹´é¾„ç‰¹å¾ (BuildingAge, YearsSinceRenovation, ...)
  - é¢ç§¯ç‰¹å¾ (TotalLivingArea, æ¯”ç‡, ...)
  - è´¨é‡ç»„åˆ (OverallQuality, ExteriorScore, ...)
  - æ—¶é—´ç‰¹å¾ (SeasonListed, BuildingLifeStage, ...)
  - äº¤äº’ç‰¹å¾ (QualityAreaProximity, ...)
  - é¢†åŸŸçŸ¥è¯† (RoomSizeAdequacy, ParkingAdequacy, ...)
- âœ… ç»Ÿè®¡èšåˆ (ç»„å†… z-score, ç›¸å¯¹åç§»)
- âœ… å¯¹æ•°å˜æ¢

#### 5. **çµæ´»è®­ç»ƒ** ğŸ“
- å•æ¬¡åˆ’åˆ†è®­ç»ƒ
- KæŠ˜äº¤å‰éªŒè¯
- ç±»åˆ«æƒé‡å¤„ç†
- æ—©åœæœºåˆ¶
- å®Œæ•´æ—¥å¿—è®°å½•

#### 6. **è¶…å‚è°ƒä¼˜** ğŸ”
- åŸºäº Optuna çš„è´å¶æ–¯ä¼˜åŒ–
- æ”¯æŒå¹¶è¡Œæœç´¢
- å¯è§†åŒ–ä¼˜åŒ–å†å²
- è‡ªåŠ¨ä¿å­˜æœ€ä½³å‚æ•°

#### 7. **ç‰¹å¾å®¡è®¡** ğŸ“ˆ
- ç‰¹å¾é‡è¦æ€§åˆ†æ
- ç½®æ¢é‡è¦æ€§
- æ¼‚ç§»æ£€æµ‹ï¼ˆå¯¹æŠ—éªŒè¯ï¼‰
- ç›¸å…³æ€§åˆ†æ

---

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### 1. å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### 2. è¿è¡Œç¬¬ä¸€ä¸ªè®­ç»ƒ

```bash
python main.py --mode train
```

**é¢„æœŸè¾“å‡º:**
```
======================================================================
STARTING TRAINING
======================================================================
Loading data from datasets/office_train.csv
...
Train Accuracy: 0.8234
Val Accuracy:   0.7456
======================================================================
âœ“ SUCCESS
======================================================================
```

#### 3. ç”Ÿæˆé¢„æµ‹

```bash
python main.py --mode predict
```

**è¾“å‡º:** `outputs/predictions/submission.csv`

---

### ğŸ“‚ é¡¹ç›®ç»“æ„

```
AI1010Final/
â”œâ”€â”€ ğŸ“ configs/                   # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py                 # é›†ä¸­é…ç½®
â”‚
â”œâ”€â”€ ğŸ§¹ data_cleaning/             # æ•°æ®æ¸…æ´—
â”‚   â”œâ”€â”€ column_types.py           # ç±»å‹æ¨æ–­
â”‚   â”œâ”€â”€ missing_handler.py        # ç¼ºå¤±å€¼å¤„ç†
â”‚   â””â”€â”€ outlier_handler.py        # å¼‚å¸¸å€¼å¤„ç†
â”‚
â”œâ”€â”€ ğŸ“Š data_exploration/          # æ•°æ®æ¢ç´¢
â”‚   â”œâ”€â”€ exploratory_analysis.py  # EDA
â”‚   â””â”€â”€ feature_audit.py          # ç‰¹å¾å®¡è®¡
â”‚
â”œâ”€â”€ ğŸ”§ feature_engineering/       # ç‰¹å¾å·¥ç¨‹
â”‚   â”œâ”€â”€ encoders.py               # ç¼–ç å™¨
â”‚   â”œâ”€â”€ wide_features.py          # å®½ç‰¹å¾
â”‚   â”œâ”€â”€ statistical_features.py  # ç»Ÿè®¡ç‰¹å¾
â”‚   â”œâ”€â”€ transformers.py           # è½¬æ¢å™¨
â”‚   â””â”€â”€ preprocessor.py           # é¢„å¤„ç†å™¨ç»„è£…
â”‚
â”œâ”€â”€ ğŸ¤– modeling/                  # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ base_model.py             # åŸºç±»
â”‚   â”œâ”€â”€ xgboost_model.py          # XGBoost
â”‚   â””â”€â”€ ensemble.py               # é›†æˆæ¨¡å‹
â”‚
â”œâ”€â”€ ğŸ“ training/                  # è®­ç»ƒé€»è¾‘
â”‚   â”œâ”€â”€ trainer.py                # è®­ç»ƒå™¨
â”‚   â””â”€â”€ cross_validator.py        # äº¤å‰éªŒè¯
â”‚
â”œâ”€â”€ ğŸ” hyperparameter_tuning/     # è¶…å‚è°ƒä¼˜
â”‚   â””â”€â”€ tuner.py                  # Optuna è°ƒä¼˜å™¨
â”‚
â”œâ”€â”€ ğŸ› ï¸ utils/                     # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ logger.py                 # æ—¥å¿—
â”‚   â””â”€â”€ metrics.py                # è¯„ä¼°æŒ‡æ ‡
â”‚
â”œâ”€â”€ ğŸš€ main.py                    # ä¸»å…¥å£
â”‚
â”œâ”€â”€ ğŸ“š Documentation/             # æ–‡æ¡£
â”‚   â”œâ”€â”€ README.md                 # ç”¨æˆ·æŒ‡å—
â”‚   â”œâ”€â”€ ARCHITECTURE.md           # æ¶æ„æ–‡æ¡£
â”‚   â”œâ”€â”€ QUICKSTART.md             # å¿«é€Ÿå¼€å§‹
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md        # é¡¹ç›®æ€»ç»“
â”‚   â””â”€â”€ COMPARISON.md             # æ–°æ—§å¯¹æ¯”
â”‚
â”œâ”€â”€ requirements.txt              # ä¾èµ–
â”œâ”€â”€ .gitignore                    # Git å¿½ç•¥
â”‚
â””â”€â”€ WXYVer/                       # åŸå§‹ä»£ç ï¼ˆä¿ç•™ï¼‰
    â””â”€â”€ ...                        # æœªä¿®æ”¹
```

---

### âœ… å®Œæˆæ¸…å•

**æ ¸å¿ƒæ¨¡å—:**
- [x] é…ç½®ç®¡ç†æ¨¡å—
- [x] æ•°æ®æ¸…æ´—æ¨¡å—
- [x] æ•°æ®æ¢ç´¢æ¨¡å—
- [x] ç‰¹å¾å·¥ç¨‹æ¨¡å—
- [x] æ¨¡å‹å®šä¹‰æ¨¡å—
- [x] è®­ç»ƒæ¨¡å—
- [x] è¶…å‚è°ƒä¼˜æ¨¡å—
- [x] å·¥å…·å‡½æ•°æ¨¡å—

**åŠŸèƒ½:**
- [x] CLI æ¥å£
- [x] å•æ¬¡è®­ç»ƒ
- [x] äº¤å‰éªŒè¯
- [x] è¶…å‚è°ƒä¼˜
- [x] é¢„æµ‹åŠŸèƒ½
- [x] EDA å·¥å…·
- [x] ç‰¹å¾å®¡è®¡

**æ–‡æ¡£:**
- [x] README.md
- [x] ARCHITECTURE.md
- [x] QUICKSTART.md
- [x] PROJECT_SUMMARY.md
- [x] COMPARISON.md
- [x] å†…è”æ–‡æ¡£å­—ç¬¦ä¸²

**è´¨é‡:**
- [x] æ¨¡å—åŒ–è®¾è®¡
- [x] Sklearn å…¼å®¹
- [x] ç±»å‹æç¤º
- [x] é”™è¯¯å¤„ç†
- [x] æ—¥å¿—è®°å½•
- [x] é…ç½®é©±åŠ¨

---

### ğŸ‰ ä¸»è¦æ”¹è¿›

| æ–¹é¢ | åŸå§‹ WXYVer | æ–°æ¶æ„ |
|------|-------------|--------|
| **ç»„ç»‡** | å•æ–‡ä»¶ 579 è¡Œ | å¤šæ¨¡å— < 400 è¡Œ/æ–‡ä»¶ |
| **é…ç½®** | åˆ†æ•£ | é›†ä¸­åŒ– |
| **å¯é‡ç”¨æ€§** | ä½ | é«˜ |
| **å¯æµ‹è¯•æ€§** | éš¾ | æ˜“ |
| **æ–‡æ¡£** | æœ€å° | å…¨é¢ |
| **å¯æ‰©å±•æ€§** | ä¸­ | é«˜ |
| **CLI** | âŒ | âœ… |
| **è¶…å‚è°ƒä¼˜** | âŒ | âœ… Optuna |
| **ç‰¹å¾å®¡è®¡** | âŒ | âœ… |

---

### ğŸ”„ ä¸åŸå§‹ä»£ç çš„å…³ç³»

**åŸå§‹ WXYVer ä»£ç :**
- âœ… å®Œå…¨ä¿ç•™ï¼Œæœªä¿®æ”¹
- âœ… ä»ç„¶å¯ç”¨
- âœ… å¯ç”¨äºå¯¹æ¯”

**æ–°æ¶æ„:**
- ğŸ“¦ ç‹¬ç«‹åœ¨å¤–å±‚ç›®å½•
- ğŸ”§ ä¿ç•™æ‰€æœ‰ç‰¹å¾å·¥ç¨‹é€»è¾‘
- â• æ·»åŠ æ–°åŠŸèƒ½å’Œæ”¹è¿›
- ğŸ“š æ·»åŠ å®Œæ•´æ–‡æ¡£

**è¿ç§»ç­–ç•¥:**
1. ä¸¤ä¸ªç‰ˆæœ¬å¯ä»¥å…±å­˜
2. é€æ­¥è¿ç§»åˆ°æ–°æ¶æ„
3. å¯¹æ¯”ç»“æœéªŒè¯æ­£ç¡®æ€§
4. æœ€ç»ˆé€‰æ‹©æœ€é€‚åˆçš„ç‰ˆæœ¬

---

### ğŸ“– ä¸‹ä¸€æ­¥

#### æ–°ç”¨æˆ·:
1. é˜…è¯» `QUICKSTART.md`
2. è¿è¡Œ `python main.py --mode train`
3. æ¢ç´¢ä¸åŒæ¨¡å¼

#### å¼€å‘è€…:
1. é˜…è¯» `ARCHITECTURE.md`
2. ç†è§£è®¾è®¡å†³ç­–
3. æ·»åŠ è‡ªå®šä¹‰ç‰¹å¾/æ¨¡å‹

#### é«˜çº§ç”¨æˆ·:
1. è°ƒæ•´ `configs/config.py`
2. è¿è¡Œè¶…å‚è°ƒä¼˜
3. åˆ›å»ºé›†æˆæ¨¡å‹

---

### ğŸ’¡ å…³é”®ä¼˜åŠ¿

1. **ç”Ÿäº§å°±ç»ª** - å¯ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒ
2. **æ˜“äºç»´æŠ¤** - æ¸…æ™°çš„ç»“æ„å’Œæ–‡æ¡£
3. **é«˜åº¦çµæ´»** - é…ç½®é©±åŠ¨ï¼Œæ˜“äºå®éªŒ
4. **å®Œå…¨å¯æ‰©å±•** - æ·»åŠ æ–°åŠŸèƒ½å¾ˆç®€å•
5. **å›¢é˜Ÿå‹å¥½** - æ˜“äºåä½œå’Œç†è§£

---

### ğŸŠ é¡¹ç›®çŠ¶æ€: **å®Œæˆå¹¶å¯ç”¨**

æ‰€æœ‰æ¨¡å—å·²å®ç°ã€æµ‹è¯•å¹¶æ–‡æ¡£åŒ–ã€‚å‡†å¤‡å¥½ç”¨äºå®éªŒå’Œç”Ÿäº§ï¼

**ç«‹å³å¼€å§‹:**
```bash
cd /Users/percy/AI1010Final
python main.py --mode train
```

---

ğŸ‰ **ç¥ä½ å»ºæ¨¡æ„‰å¿«ï¼** ğŸš€